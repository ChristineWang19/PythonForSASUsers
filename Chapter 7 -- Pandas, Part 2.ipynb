{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 -- Pandas, Part2\n",
    "#### Slicing, Dicing, & Subsetting; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual pre-amble to get packages loaded into the namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import randn\n",
    "from pandas import Series, DataFrame, Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the .csv file with the reader read_csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a DataFrame with the read_csv() method\n",
    "\n",
    "file_loc = \"C:\\Data\\\\uk_accidents.csv\"\n",
    "df = pd.read_csv(file_loc,low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266776, 27)\n",
      "(266752, 27)\n"
     ]
    }
   ],
   "source": [
    "# dropping rows in the original accidents DataFrame\n",
    "\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing, Dicing, and Subseting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Our DataFrame is a time series.  This often means we need to understand durations, convert a time series to a different frequency, or make adjustments based on non-standard intervals like the 5 day business week.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.sort_values(by='Date').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.set_index('Date', drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Indexed returned when sorted\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1/9/2015', '1/9/2015', '2/23/2015', '2/23/2015', '2/23/2015',\n",
       "       '2/11/2015', '2/11/2015', '2/23/2015', '2/23/2015', '4/18/2015',\n",
       "       ...\n",
       "       '8/30/2015', '11/29/2015', '11/29/2015', '11/29/2015', '7/26/2015',\n",
       "       '7/26/2015', '12/31/2015', '7/28/2015', '7/28/2015', '7/15/2015'],\n",
       "      dtype='object', name='Date', length=266752)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexed returned when NOT-sorted\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([['cold','slow', np.nan, 2., 6., 3.], \n",
    "                    ['warm', 'medium', 4, 5, 7, 9],\n",
    "                    ['hot', 'fast', 9, 4, np.nan, 6],\n",
    "                    ['cool', None, np.nan, np.nan, 17, 89],\n",
    "                    ['cool', 'medium', 16, 44, 21, 13],\n",
    "                    ['cold', 'slow', np.nan, 29, 33, 17]],\n",
    "                    columns=['col1', 'col2', 'col3', 'col4', 'col5', 'col6'],\n",
    "                    index=['f','b','c','d','e','f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Range for rows with dates between 25Dec15 and 31Dec15\n",
    "df.loc['12/25/2015':'12/31/2015']\n",
    "\n",
    "print('There were {} accidents between 25Dec2015 and 31Dec2015:'.format(len(df.loc['2015-12-25'-'2015-12-31'])))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We often need to slice, dice, and subset data.  DataFrames provide indexing methods to accomplish these tasks.  They are:\n",
    "\n",
    "    1. loc() method which is mainly used with labels (either column or row)\n",
    "    2. iloc() method which is mainly an integer-based method\n",
    "    3. .ix() method which supports a combination of the loc() and iloc() methods\n",
    "    \n",
    "Presently, the DataFrame df has its rows indexed by the RangeIndex (0 to 266775) built when the DataFrame was created. And because the UK accidents data set is a time-series, it makes sense to index the rows by date.  The Pandas documentation refers to axis, where axis 0 is the row dimension and axis 1 is the column dimension.  This will make more sense in the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a new column to the dataframe \n",
    "\n",
    "df['id'] = list(range(len(df.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.set_index('Date', drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The syntax for the .loc() method is:\n",
    "\n",
    "    df.loc[row selection, column selection]\n",
    "    \n",
    "With the index set to 'Date' the .loc() method is able to select rows based on the index value of any row.  The example in the cell below selects the rows with date of Dec. 25, 2015. This particular data has multiple accidents reports for each day, so that the index column values are not unique.  \n",
    "\n",
    "The absence of a column selection is an implicit request for all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc['2015-12-25'].head(2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If the .loc() method returns a single row, then the result is a Series. In our case, we have multiple accidents per day in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(df.loc['2015-12-25']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The built-in function len() returns of the length of the row slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many accidents occured on Christman Day?\n",
    "\n",
    "print('There were {} accidents on Christmas 2015.'.format(len(df.loc['2015-12-25'])))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You can use a range for both row and column selection.  In the example below, rows are from the data range (start and end dates) inclusive.  This is equivalent to SAS' WHERE clause:\n",
    "\n",
    "    (where=(date between \"25Dec2015\"d and \"31Dec2015\"d))\n",
    "    \n",
    "The SAS example is shown below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "61       data _null_ (keep=date);\n",
    "62          set uk_accidents(where=(date between \"25Dec2015\"d and \"31Dec2015\"d)) end=end;\n",
    "63       retain count 0;\n",
    "64       \n",
    "65       count+1;\n",
    "66          if end then put 'There were ' count' accidents between 25Dec15 and 31Dec15';\n",
    "\n",
    "There were 53373 accidents between 25Dec15 and 31Dec15"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Notice the implied boolean variable end= on the SET statement above.  The automatic variable 'end' is initialized to 0 and set to 1 when the last observation in the data set is read.  The syntax:\n",
    "    \n",
    "    if end ....\n",
    "\n",
    "in SAS is identical to:\n",
    "\n",
    "    if end = 1 ....\n",
    "    \n",
    "The Pythonic way would be:\n",
    "\n",
    "    if end = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns rows between 15Dec2015 and 31DecJan2015 and the associated 'Number_of_Vehicles' and 'Time' values\n",
    "\n",
    "df.loc['2015-12-25':'2015/12/31', ['Number_of_Vehicles', 'Time']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns rows between 15Dec2015 and 31DecJan2015 and the associated 'Number_of_Vehicles' and 'Time' values\n",
    "\n",
    "df.loc['2015-12-25':'2015/12/31', ['Number_of_Vehicles', 'Time']].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The next two examples use a boolean mask with .loc() method.  The mask is a Series of True/False values the .loc() indexer uses to select those rows where the condition(s) evaluate True.  Notice we are not relying on the indexed column Date, however, this column is returned since it is remains set as the index for the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selection with boolean conditions using .loc() method \n",
    "# All rows for Saturday, speed limit > 70 and the associated 'Time' values\n",
    "\n",
    "df.loc[(df['Day_of_Week'] == 6) & (df['Speed_limit'] >= 70)].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A boolean mask used to select the records for Saturday, speed limit > 70, and the associated column 'Time'\n",
    "\n",
    "df.loc[(df['Day_of_Week'] == 6) & (df['Speed_limit'] >= 70), ['Time']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataFrame describe method\n",
    "\n",
    "df.describe(percentiles=None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SAS procedures like MEANS and UNIVARITE will return similiar summary statistics.  However, the output is on a variable basis, producing a large amount of output."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Sex_of_Driver column is a key classifier, and we know -1 is used to indicate missing and the value 3 is used to indicate unknown.  The unique() method is analogous to PROC SQL's select distinct <variable-list> statement.  Both return a list of unique values for the column(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# similar to PROC SQL; select distinct, the unique() method finds unique values for a variable\n",
    "\n",
    "df.Sex_of_Driver.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# similar to PROC SQL; select distinct, the unique() method finds unique values for a variable\n",
    "\n",
    "df.Sex_of_Driver.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What is needed, is both distinct values and a count.  The value_counts() method is analogus to PROC FREQ.  Later in this chapter, we will see additional DataFrame methods like crosstab() to render results in a less spartan fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.Sex_of_Driver.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "50       proc freq data = uk_accidents;\n",
    "51       tables sex_of_driver / missing missprint nocum nopercent;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From the SAS example above, output from PROC PRINT\n",
    "#C:\\Users\\randy\\Anaconda3\\output\n",
    "\n",
    "Image(filename='Anaconda3\\\\output\\\\freq_sex_of_driver.JPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Square brackets [ ] are used to subset a Python object.  This syntax is illustrated in the cell below.  df1 is a new DataFrame which contains three columns and all rows from DataFrame df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# selecting all columns by name\n",
    "\n",
    "df1 = df[['Age_of_Driver', 'Sex_of_Driver', 'Time']]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analog SAS program is below.  Notice how the KEEP list is associated with the SET statement which directs SAS to read just the 3 columns from the input data set.  The KEEP list on the input data set returns the same results but instead reads all of the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "52       data df1;\n",
    "53          set uk_accidents(keep = age_of_driver sex_of_driver date);\n",
    "\n",
    "NOTE: 266776 observations were read from \"WORK.uk_accidents\"\n",
    "NOTE: Data set \"WORK.df1\" has 266776 observation(s) and 3 variable(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Wrong syntax example\n",
    "df2 = df[[('Sex_of_Driver' == 2) & ('Age_of_Driver' >= 70)]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We often wish to slice by row and column.  Earlier you saw examples of boolean operators.  Using the column label-syntax illustrated above raises an error in the example below.  \n",
    "\n",
    "The Python interpreter is attempting to evaluate a boolean comparision of the literal string 'Age_of_Driver' equal to or greater than 70.  Clearly, we need another syntax to accomplishing the slicing operation."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The example below illustrates the use of column as an attribute.  You utilize the square brackets to create a slice.  This creates a DataFrame selecting the rows expressed by the boolean condition.  Observe how the name of the DataFrame appears before the square brackets [ ].  Without this object name, the syntax produces a list as shown in the example two cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Correct syntax\n",
    "df2 = df[(df.Sex_of_Driver == 2) & (df.Age_of_Driver >= 70)]\n",
    "print(type(df2))\n",
    "print(len(df2))\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = [(df.Sex_of_Driver == 2) & (df.Age_of_Driver >= 70)]\n",
    "type(df3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "*************WE ARE SUBSETTING AND CREATING NEW DATA FRAMES HERE********************************\n",
    "\n",
    "We often need to create sub-sets of a DataFrame object.  The use cases for sub-setting with SAS is generally with the SET and WHERE statements, or IF/THEN DO blocks with an explicit OUTPUT statement.  Of course, both languages have multiple methods for accomplishing the same tasks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3[0][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Female Drivers with age >= 70: {0}\".format(len(df2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
