{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 09 -- Panda Time Series and Date Handling--DRAFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics Covered:\n",
    "\n",
    "<a href=\"http://nbviewer.jupyter.org/github/RandyBetancourt/PythonForSASUsers/blob/master/Chapter%2009%20--%20Panda%20Time%20Series%20and%20Date%20Handling#Definitions.ipynb\"> Definitions </a>\n",
    "\n",
    "<a href=\"http://nbviewer.jupyter.org/github/RandyBetancourt/PythonForSASUsers/blob/master/Chapter%2009%20--%20Panda%20Time%20Series%20and%20Date%20Handling\"> Creating and manipulating a fixed-frequency of datetime spans </a>\n",
    "\n",
    "Convert time series from one frequency to another\n",
    "\n",
    "Increment 'non-standard' datetimes intervals (e.g. business week)\n",
    "\n",
    "Time Series Walk-Through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chapter 8, <a href=\"http://nbviewer.jupyter.org/github/RandyBetancourt/PythonForSASUsers/blob/master/Chapter%2008%20--%20Python%20Date%2C%20Time%2C%20and%20%20Timedelta%20Objects.ipynb\"> Understanding Date Time and TimeDelta objects </a> provided a short introduction to Python's built-in datetime capabilities.  In this chapter we illustrate pandas time series and date handling.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import date, time, datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame, Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "\n",
    "To begin, we need to distinguish between object types used to represent datetimes.  While a bit pandantic,, it helps to clarify the behaviors of these objects.  panda Time Series utilize NumPy datetime64 and timedelta64 dtypes.\n",
    "\n",
    "Recall, you can always return an object's type with the type method:\n",
    "\n",
    "    type()\n",
    "    \n",
    "Examples work better than prose.  Consider the assignments in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_date = date(2016, 10, 24)\n",
    "a_datetime = datetime(2016, 10, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-24\n",
      "2016-10-24 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(a_date)\n",
    "print(a_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_date == a_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surpringly the date and datetime objects are not logically equivalent.  After all, they use different 'counters'.  Further, \n",
    "the cell below illustrates they are are from two different classes from the datetime module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n",
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "print(type(a_date))\n",
    "print(type(a_datetime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in case you were wondering about SAS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````\n",
    "    56       data _null_;\n",
    "    57       \n",
    "    58       a_date = '24Oct2016'd;\n",
    "    59       a_datetime = '24Oct2016:00:00:00'dt;\n",
    "    60       \n",
    "    61       if a_date = a_datetime then\n",
    "    62          put 'True';\n",
    "    63       else\n",
    "    64          put 'False';\n",
    "\n",
    "    False\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python also distinquishes between datetime and datestamps.  Again, examples work better than prose.  The path.getatime() method returns the access time for a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = \"lines.html\"\n",
    "from os import path\n",
    "\n",
    "a_time = path.getatime(file)\n",
    "\n",
    "af_time = datetime.fromtimestamp(a_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value returned: 1477433492.8224854\n",
      "value returned: 2016-10-25 16:11:32.822485\n"
     ]
    }
   ],
   "source": [
    "print('value returned:', a_time)\n",
    "print('value returned:', af_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type for a_time is <class 'float'> and Type for af_time is <class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "print('Type for a_time is', type(a_time), 'and Type for af_time is', type(af_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A timestamp is time value that represents a count of the number of seconds from the start of an epoch.  This is similiar to SAS datetime values that represent an off-set from an epoch beginning at midnight.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdt = pd.Timestamp('2016-10-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.tslib.Timestamp"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and manipulating a fixed-frequency of date and time spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pd.date_range() method generates a DateTime Index which is applied to a panda Series or DataFrame to provide datetime interval indexing.  We will see examples of its construction methods.  And later we will utilize indexers taking advange of the Date TimeIndex.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = pd.date_range('1/1/2016', periods=90, freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 10 dates in the DateTimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-01-01', '2016-01-02', '2016-01-03', '2016-01-04',\n",
       "               '2016-01-05', '2016-01-06', '2016-01-07', '2016-01-08',\n",
       "               '2016-01-09', '2016-01-10'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-stamped data for pandas represent a point in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Period being inferred from the datetime string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2016-01-01', 'D')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2016-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._period.Period"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.Period('2016-01-01'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Period being set explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2016-05-01', 'D')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Period('2016-05', freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamp and Period can be an index.  Coerced into PeriodIndex and DateTimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = [pd.Timestamp('2012-05-01'), pd.Timestamp('2012-05-02'), pd.Timestamp('2012-05-03')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2012-05-01 00:00:00'),\n",
       " Timestamp('2012-05-02 00:00:00'),\n",
       " Timestamp('2012-05-03 00:00:00')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " ts = pd.Series(np.random.randn(3), dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-05-01    0.475898\n",
       "2012-05-02   -0.039289\n",
       "2012-05-03   -0.909969\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.tseries.index.DatetimeIndex"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-05-01', '2012-05-02', '2012-05-03'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert date string to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-11-30 00:00:00')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('2016/11/30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.tslib.Timestamp"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.to_datetime('2016/11/30'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Convert date string to Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-11-30 00:00:00')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp('2016/11/30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.tslib.Timestamp"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.Timestamp('2016/11/30'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can assemble a DataFrame by using strings and integers for columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'year': [2014, 2015, 2016],\n",
    "                   'month': [1, 2, 3],\n",
    "                   'day': [1,2,3,]})\n",
    "df1 = pd.to_datetime(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date, time\n",
    "start = datetime(2016, 1, 1)\n",
    "end = datetime(2016, 12, 31)\n",
    "rng = pd.date_range(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-01-01', '2016-01-02', '2016-01-03', '2016-01-04',\n",
       "               '2016-01-05', '2016-01-06', '2016-01-07', '2016-01-08',\n",
       "               '2016-01-09', '2016-01-10',\n",
       "               ...\n",
       "               '2016-12-22', '2016-12-23', '2016-12-24', '2016-12-25',\n",
       "               '2016-12-26', '2016-12-27', '2016-12-28', '2016-12-29',\n",
       "               '2016-12-30', '2016-12-31'],\n",
       "              dtype='datetime64[ns]', length=366, freq='D')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = datetime(2016, 1, 1)\n",
    "end = datetime(2016, 12, 31)\n",
    "b_rng = pd.bdate_range(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-01-01', '2016-01-04', '2016-01-05', '2016-01-06',\n",
       "               '2016-01-07', '2016-01-08', '2016-01-11', '2016-01-12',\n",
       "               '2016-01-13', '2016-01-14',\n",
       "               ...\n",
       "               '2016-12-19', '2016-12-20', '2016-12-21', '2016-12-22',\n",
       "               '2016-12-23', '2016-12-26', '2016-12-27', '2016-12-28',\n",
       "               '2016-12-29', '2016-12-30'],\n",
       "              dtype='datetime64[ns]', length=261, freq='B')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-01-29', '2016-02-29', '2016-03-31', '2016-04-29',\n",
       "               '2016-05-31', '2016-06-30', '2016-07-29', '2016-08-31',\n",
       "               '2016-09-30', '2016-10-31', '2016-11-30', '2016-12-30'],\n",
       "              dtype='datetime64[ns]', freq='BM')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range(start, end, freq='BM')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "ts.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-01-29', '2016-02-29', '2016-03-31', '2016-04-29',\n",
       "               '2016-05-31'],\n",
       "              dtype='datetime64[ns]', freq='BM')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[:5].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Returns the nth, i.e. 2 = every other one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-01-29   -1.416549\n",
       "2016-03-31    1.688049\n",
       "2016-05-31    0.650461\n",
       "2016-07-29   -1.083026\n",
       "2016-09-30    0.219029\n",
       "2016-11-30   -0.591642\n",
       "Freq: 2BM, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-01-29   -1.416549\n",
       "2016-07-29   -1.083026\n",
       "Freq: 6BM, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[::6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Walk-Through\n",
    "\n",
    "We can begin combining features covered in previous chapters to conduct a walk-through of an actual time-series analysis.  The data is the FHFA House Price Index (HPI) \n",
    "\n",
    "It is a broad measure of the movement of single-family house prices. The HPI is a weighted, repeat-sales index, meaning that it measures average price changes in repeat sales or refinancings on the same properties. This information is obtained by reviewing repeat mortgage transactions on single-family properties whose mortgages have been purchased or securitized by Fannie Mae or Freddie Mac.  \n",
    "\n",
    "Details about the data and how it is organized can be found <a href=\"https://catalog.data.gov/dataset/fhfa-house-price-indexes-hpis\"> here </a>. \n",
    "\n",
    "This time series begins January 1991 and end August 2016.  Both the seasonally adjusted index 'index_sa' and the non-seaonally adjusted index 'index_nsa' set the index value at 100 for January 1991.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .csv file is two parts.  Part 1, rows 2 to 3079 are records for the aggregate market groups at the Census Division level.  The frequency interval is monthly.\n",
    "\n",
    "Part 2, rows 3080 to 96,243 are more granular with 4 values for level, 'MSA', 'State', 'USA or Census Division', and 'Puerto Rico'.  The frequency interval is quarterly. \n",
    "\n",
    "Start with the U.S. portion by reading part 1 of the file.  The pd.read_csv method uses the one required arguement, the input file name to create the DataFrame 'df_all'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"C:\\Data\\\\HPI_master.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first 5 rows to determine if the read_csv() method is giving the expected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpi_type</th>\n",
       "      <th>hpi_flavor</th>\n",
       "      <th>frequency</th>\n",
       "      <th>level</th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_id</th>\n",
       "      <th>yr</th>\n",
       "      <th>period</th>\n",
       "      <th>index_nsa</th>\n",
       "      <th>index_sa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99320</th>\n",
       "      <td>developmental</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>160.23</td>\n",
       "      <td>158.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99321</th>\n",
       "      <td>developmental</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>159.54</td>\n",
       "      <td>161.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99322</th>\n",
       "      <td>developmental</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>155.14</td>\n",
       "      <td>152.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99323</th>\n",
       "      <td>developmental</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>150.61</td>\n",
       "      <td>154.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99324</th>\n",
       "      <td>developmental</td>\n",
       "      <td>purchase-only</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>165.45</td>\n",
       "      <td>163.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hpi_type     hpi_flavor  frequency        level   place_name  \\\n",
       "99320  developmental  purchase-only  quarterly  Puerto Rico  Puerto Rico   \n",
       "99321  developmental  purchase-only  quarterly  Puerto Rico  Puerto Rico   \n",
       "99322  developmental  purchase-only  quarterly  Puerto Rico  Puerto Rico   \n",
       "99323  developmental  purchase-only  quarterly  Puerto Rico  Puerto Rico   \n",
       "99324  developmental  purchase-only  quarterly  Puerto Rico  Puerto Rico   \n",
       "\n",
       "      place_id    yr  period  index_nsa  index_sa  \n",
       "99320       PR  2015       2     160.23    158.62  \n",
       "99321       PR  2015       3     159.54    161.27  \n",
       "99322       PR  2015       4     155.14    152.81  \n",
       "99323       PR  2016       1     150.61    154.71  \n",
       "99324       PR  2016       2     165.45    163.82  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to combine the year and period fields into a DataTime Stamp.  The .csv file in cell #xx above is read without any datetime parsing for the fields, 'yr' and 'period'.  We could post-process these fields to construct the appropriate date timestamp values.  \n",
    "\n",
    "A better approach is below.  The parse_dates= argument allows a <a href=\"http://nbviewer.jupyter.org/github/RandyBetancourt/PythonForSASUsers/blob/master/Chapter%2002%20--%20Data%20Structures.ipynb#dictionary\"> dictionary </a> object with the key being the arbitrary name of the new column created and the key values indicating which fields are to be read in the .csv file.  Recall that Python indexes have a start position of 0.  In the .csv file, these fields are the 7th and 8th.\n",
    "\n",
    "Sometimes, you may need to create your own date-parser, analogous to building a user-defined SAS INFORMAT to map field values into a datetime object.  This is particularly true in cases where the date value is stored as component values in multiple fields.   \n",
    "\n",
    "## url for custom date_parser here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\Data\\\\HPI_master.csv\",\n",
    "                 parse_dates={'date_idx': [6,7]},\n",
    "                 nrows=3080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3080, 9)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_idx      False\n",
       "hpi_type      False\n",
       "hpi_flavor    False\n",
       "frequency     False\n",
       "level         False\n",
       "place_name    False\n",
       "place_id      False\n",
       "index_nsa     False\n",
       "index_sa      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the string 'date_idx' column constructed through the date_parser to a datetime value.  Set the 'date' column as the index on the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date_idx'])\n",
    "df.set_index(\"date\", inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing on the datetime column 'date' creates a 'time-aware' DateTimeIndex.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1991-01-01', '1991-02-01', '1991-03-01', '1991-04-01',\n",
       "               '1991-05-01', '1991-06-01', '1991-07-01', '1991-08-01',\n",
       "               '1991-09-01', '1991-10-01',\n",
       "               ...\n",
       "               '2015-11-01', '2015-12-01', '2016-01-01', '2016-02-01',\n",
       "               '2016-03-01', '2016-04-01', '2016-05-01', '2016-06-01',\n",
       "               '2016-07-01', '2016-08-01'],\n",
       "              dtype='datetime64[ns]', name='date', length=3080, freq=None)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the first and last date values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest date is: 1991-01-01 00:00:00\n",
      "Latest date is: 2016-08-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print('Earliest date is:', df.date.min())\n",
    "print('Latest date is:', df.date.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from cell #xx above, that we have several categorical columns.  So we need to understand their levels.  Earlier, we saw the .describe() method used for numerical columns.  In this example, specifying the 'include=' argument provides a description of string columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'place_name' column has 10 unique levels or values.  We can examine these values with the .unique() attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.place_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting an index on the column 'place_name', you can create a sub-set of the DataFrame 'df_all' to include just those rows for the U.S.  The .loc indexer allows row slicing which is covered in detail <a href=\"http://nbviewer.jupyter.org/github/RandyBetancourt/PythonForSASUsers/blob/master/Chapter%2005%20--%20Understanding%20Indexes.ipynb#.loc-Indexer\"> here </a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.set_index('place_name', inplace=True, drop=False)\n",
    "df_us = df_all.loc['United States']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Time series data lends itself well to plotting.  Here we use the bokeh package to plot the non-seasonal home price index for three regions.  \n",
    "\n",
    "Start by plotting the series for the entire U.S.  For this, we use the 'df_us' DataFrame created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bokeh.charts\n",
    "import bokeh.charts.utils\n",
    "import bokeh.io\n",
    "import bokeh.models\n",
    "import bokeh.palettes\n",
    "import bokeh.plotting\n",
    "\n",
    "# Display graphics in this notebook\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = bokeh.charts.Line(df_us, x='date_idx', y='index_nsa', color='firebrick',  title=\"Home Price Values in the U.S.\")\n",
    "\n",
    "# Display it\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_us_3 = df_all.loc[['West South Central Division', 'United States', 'Pacific Division']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the Great Recession of 2008-2010, home prices across the U.S. declined dramatically.  Home prices in the Pacific region, which includes California, grew significantly more than the U.S. as a whole.  Aggregate U.S. home prices have regained all of their price losses since then and the Pacific and West South Central regions are not too far behind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = bokeh.charts.Line(df_us_3, x='date_idx', y='index_nsa', color='place_name',\n",
    "                      legend=\"top_left\")\n",
    "\n",
    "bokeh.io.show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue this analysis, we need to read the remainder of the .csv containing state-level data.  In this instance, we use to 'skiprows=' argument to begin reading on row 3084.  We specify the columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning on row 3081, there are no values for the field 'index_sa'.  We re-read starting with row 3081 to the end of the file.  And since the default is to key off the column names, we will need to supply the column mappings.  And because we are reading from an arbirary start point, we supply a  <a href= \"http://nbviewer.jupyter.org/github/RandyBetancourt/PythonForSASUsers/blob/master/Chapter%2002%20--%20Data%20Structures.ipynb#tuple\"> tuple </a> of names.  Header=None is needed in order to prevent the reader from attempting to build column names at row position nrows-1, which in our case contains data values.\n",
    "\n",
    "There are no values for seasonally adjusted prices beyond rows 3081."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_states = pd.read_csv(file_loc2, low_memory=False,\n",
    "            parse_dates={'date_idx': [6,7]},\n",
    "            skiprows=3083,\n",
    "            usecols=(0, 1, 2, 3, 4, 5, 6, 7, 8),\n",
    "            names=('hpi_type', 'hpi_flavor', 'frequency', 'level', 'place_name', 'place_id', 'yr', 'period', 'index_nsa'),\n",
    "            header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states.level.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What imputation method should be used to treat missing data?.  We can start by finding the range of values.  Like most languages, there are multiple methods for accomplishing a given task.  \n",
    "\n",
    "We can set an index on the 'index_nsa' values and find the maximum and minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states.set_index('index_nsa', inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Max value for index_nsa:', df_states['index_nsa'].max())\n",
    "print('Min value for index_nsa:', df_states['index_nsa'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can sort the values and use the <a href=\"http://nbviewer.jupyter.org/github/RandyBetancourt/PythonForSASUsers/blob/master/Chapter%2005%20--%20Understanding%20Indexes.ipynb#.iloc-Indexer\"> iloc </a> indexer.  \n",
    "\n",
    "Recall that the .iloc indexer returns slices by index position similiar to the way \\_n\\_ in SAS behaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort and Sort Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good opportunity to understand the sort behaviors for DataFrames.  We begin by examing what I call the default sort behavior.  We have provided the minimum argument to the .sort_values attribute, the sort key in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_srt = df_states.sort_values('index_nsa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By examing the first the first two rows of the sorted DataFrame, 'states_srt', we can see the default sort sequence is ascending.  Of course, by reading the doc for <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\"> pandas.DataFrame.sort_values </a> we could see this as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_srt.iloc[[0, 1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that the panda default sort sequence places NaN's last in the sort sequence by default.  So this can be an alternative to using boolean operators and the .loc() method to detect missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_srt.iloc[[-1, -2],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there were 2 NaN's found, we can use the .iloc indexer to return 3rd and 4th row from the 'bottom' of the DataFrame, displaying the 2 highest values for the column 'index_nsa'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_srt.iloc[[-3, -4], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And naturally, we can completely alter the organization of the data_frame by supplying arguments and values to the sort_values attribute.  In the example below we sort using a descending sort sequence and placing the missing values at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states_srt2 = df_states.sort_values('index_nsa', ascending=False, na_position='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two rows in the DataFrame 'states_srt2' contain the 2 NaN's for the column 'index_nsa' values.  The next 2 rows contain the highest values for 'index_nsa'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states_srt2.iloc[0:4,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start a new dataframe here for the frequency shifting example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the aggregate U.S. housing index (DataFrame 'df_us') created above, the value for the 'frequency' column is monthly. So we need to find what the frequency value is for the 'states_srt2' DataFrame.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states_srt2.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states_srt2['level'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### have not introduced groupby and most of the examples are in chapter 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states_srt2.groupby('level').count() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Looking at the data for the latest month in the Time Series, we want to find the highest and lowest values for a given place and plot these values over time and use the aggregate U.S. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states.sort_values('place_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states.set_index('place_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_states.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "la = df_states.loc['Los Angeles-Long Beach-Glendale, CA (MSAD)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Navigation\n",
    "\n",
    "<a href=\"http://nbviewer.jupyter.org/github/RandyBetancourt/PythonForSASUsers/tree/master/\"> Return to Chapter List </a>    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
